{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "import scipy\n",
    "import scipy.stats as sts\n",
    "from scipy.stats import norm\n",
    "import numpy.random as nrnd\n",
    "from sklearn import metrics\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Activation, Input, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras_tqdm import TQDMNotebookCallback as ktqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_classes = \"/home/tore/venv/homes.di.unimi.it/classes/GM12878.csv\"\n",
    "path_epigenomic = \"/home/tore/venv/homes.di.unimi.it/epigenomic-data/GM12878.csv\"\n",
    "path_sequences = \"/home/tore/venv/homes.di.unimi.it/sequences/GM12878.csv\"\n",
    "\n",
    "classes = pd.read_csv(path_classes, names = [\"Titles\"])\n",
    "epigenomic = pd.read_csv(path_epigenomic, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (classes.join(epigenomic))\n",
    "data = data.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"Titles\"] == \"A-P\") | (data[\"Titles\"] == \"I-P\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10816, 73891)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = data[data[\"Titles\"] == \"A-P\"]\n",
    "ip = data[data[\"Titles\"] == \"I-P\"]\n",
    "len(ap), len(ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Testing Sets\n",
    "\n",
    "    Since I-Ps are seven times more circa than A-Ps, a more fair way to use datas is needed.\n",
    "    One idea could be separating I-P in seven parts each of 10k elements and running seven batches of training / testing, each one with its own process of k-fold cross evaluation.\n",
    "    Another one could "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
