{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "import scipy\n",
    "import scipy.stats as sts\n",
    "from scipy.stats import norm\n",
    "import numpy.random as nrnd\n",
    "from sklearn import metrics\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Activation, Input, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras_tqdm import TQDMNotebookCallback as ktqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_classes = \"/home/tore/venv/homes.di.unimi.it/classes/GM12878.csv\"\n",
    "path_epigenomic = \"/home/tore/venv/homes.di.unimi.it/epigenomic-data/GM12878.csv\"\n",
    "path_sequences = \"/home/tore/venv/homes.di.unimi.it/sequences/GM12878.csv\"\n",
    "\n",
    "classes = pd.read_csv(path_classes, names = [\"Titles\"])\n",
    "epigenomic = pd.read_csv(path_epigenomic, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (classes.join(epigenomic))\n",
    "data = data.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"Titles\"] == \"A-P\") | (data[\"Titles\"] == \"I-P\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10816, 73891)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = data[data[\"Titles\"] == \"A-P\"]\n",
    "ip = data[data[\"Titles\"] == \"I-P\"]\n",
    "len(ap), len(ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Testing Sets\n",
    "\n",
    "    Since I-Ps are seven times more circa than A-Ps, a more fair way to use datas is needed.\n",
    "    Ideas:\n",
    "        > Under-sampling\n",
    "        > Keeping training ratio 7:1\n",
    "        \n",
    "    Use numpy to convert each row of the frame in a np.array\n",
    "    \n",
    "    Dataframe hase shape (10816, 102) so, concerning the structure of the network:\n",
    "        > 101 input neurons for the 0-column holds the labels\n",
    "        > 1 output neuron\n",
    "        \n",
    "### Under-sampling attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_under = (shuffle(ip))[:len(ap)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_arr, ip_arr = ap.values, ip_under.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A-Ps and I-Ps should now be cropped together in order to have the full training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ip, y_ip = ip_under.values[:, ip_under.columns != \"Titles\"], ip_under.values[:, ip_under.columns == \"Titles\"]\n",
    "x_ap, y_ap = ap.values[:, ap.columns != \"Titles\"], ap.values[:, ap.columns == \"Titles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set, y_set = np.concatenate((x_ap, x_ip)), np.concatenate((y_ap, y_ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_set, \n",
    "    y_set, \n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15142, 101), (6490, 101), (15142, 1), (6490, 1))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7:1 Ratio attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
